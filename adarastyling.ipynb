{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbfb958",
   "metadata": {},
   "source": [
    "# First aproach & Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "fb9028b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "e4be678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c530845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"./the_office_lines_scripts.csv\"\n",
    "json_file = \"./stopwords.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "ca87a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59904</th>\n",
       "      <td>59905</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>It all seems so very arbitrary. I applied for ...</td>\n",
       "      <td>Creed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59905</th>\n",
       "      <td>59906</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>I just feel lucky that I got a chance to share...</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>59907</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>114</td>\n",
       "      <td>I���m happy that this was all filmed so I can ...</td>\n",
       "      <td>Phyllis</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59907</th>\n",
       "      <td>59908</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>I sold paper at this company for 12 years. My ...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59908</th>\n",
       "      <td>59909</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>116</td>\n",
       "      <td>I thought it was weird when you picked us to m...</td>\n",
       "      <td>Pam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59909 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  season  episode  scene  \\\n",
       "0          1       1        1      1   \n",
       "1          2       1        1      1   \n",
       "2          3       1        1      1   \n",
       "3          4       1        1      1   \n",
       "4          5       1        1      1   \n",
       "...      ...     ...      ...    ...   \n",
       "59904  59905       9       23    112   \n",
       "59905  59906       9       23    113   \n",
       "59906  59907       9       23    114   \n",
       "59907  59908       9       23    115   \n",
       "59908  59909       9       23    116   \n",
       "\n",
       "                                               line_text   speaker  deleted  \n",
       "0      All right Jim. Your quarterlies look very good...   Michael    False  \n",
       "1             Oh, I told you. I couldn't close it. So...       Jim    False  \n",
       "2      So you've come to the master for guidance? Is ...   Michael    False  \n",
       "3             Actually, you called me in here, but yeah.       Jim    False  \n",
       "4        All right. Well, let me show you how it's done.   Michael    False  \n",
       "...                                                  ...       ...      ...  \n",
       "59904  It all seems so very arbitrary. I applied for ...     Creed    False  \n",
       "59905  I just feel lucky that I got a chance to share...  Meredith    False  \n",
       "59906  I���m happy that this was all filmed so I can ...   Phyllis    False  \n",
       "59907  I sold paper at this company for 12 years. My ...       Jim    False  \n",
       "59908  I thought it was weird when you picked us to m...       Pam    False  \n",
       "\n",
       "[59909 rows x 7 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts_df = pd.read_csv(csv_file, encoding=\"utf_8\")\n",
    "scripts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "fa2b2508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59909.000000</td>\n",
       "      <td>59909.000000</td>\n",
       "      <td>59909.000000</td>\n",
       "      <td>59909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29955.000000</td>\n",
       "      <td>5.348178</td>\n",
       "      <td>11.558597</td>\n",
       "      <td>27.143852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17294.382975</td>\n",
       "      <td>2.389427</td>\n",
       "      <td>6.986208</td>\n",
       "      <td>17.860616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14978.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29955.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44932.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59909.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        season       episode         scene\n",
       "count  59909.000000  59909.000000  59909.000000  59909.000000\n",
       "mean   29955.000000      5.348178     11.558597     27.143852\n",
       "std    17294.382975      2.389427      6.986208     17.860616\n",
       "min        1.000000      1.000000      1.000000      1.000000\n",
       "25%    14978.000000      3.000000      5.000000     14.000000\n",
       "50%    29955.000000      5.000000     11.000000     25.000000\n",
       "75%    44932.000000      7.000000     18.000000     37.000000\n",
       "max    59909.000000      9.000000     26.000000    116.000000"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "32d4f11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' print(scripts_df.iloc[9870])\\nscripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\", and \", \",\")\\nscripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\", &\", \",\")\\nscripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\"&\", \",\")\\nscripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\"and \", \",\")\\nscripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\",\", \" - \")\\ndf2 = scripts_df[scripts_df[\"speaker\"].str.contains(\"- \") == True]\\ndf2 '"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" print(scripts_df.iloc[9870])\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\", and \", \",\")\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\", &\", \",\")\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\"&\", \",\")\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\"and \", \",\")\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(\",\", \" - \")\n",
    "df2 = scripts_df[scripts_df[\"speaker\"].str.contains(\"- \") == True]\n",
    "df2 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "0147727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>thorough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>thoroughly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>wonder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0             a\n",
       "1         about\n",
       "2         above\n",
       "3         after\n",
       "4         again\n",
       "..          ...\n",
       "779    thorough\n",
       "780  thoroughly\n",
       "781       three\n",
       "782        well\n",
       "783      wonder\n",
       "\n",
       "[784 rows x 1 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_df = pd.read_json(json_file)\n",
    "stop_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "40190dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>keeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "count     784\n",
       "unique    781\n",
       "top     keeps\n",
       "freq        2"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f30a65",
   "metadata": {},
   "source": [
    "# Main data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474add5d",
   "metadata": {},
   "source": [
    "For an easy acces of the information we can transform the scripts_df in three main variables \"characters_data\": Wich is a dictionary capable of telling all the seasons/episodes in wich a character was present, it also has a place for season metadata to solve the tasks of this option; \"said_jokes\": A list of the posible scripts_df positions with a \"That´s what she said\" joke in the line_text column; \"season_episodes\": A dictionary with the seasons as keys and a list of episodes as data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffabea7b",
   "metadata": {},
   "source": [
    "characters_data format = { \n",
    "    character_name(string): { \n",
    "        season_number(integer):{ \n",
    "            \"episodes_in_season\": [int, int,...], \n",
    "            \"metadata_of_the_season\": { \n",
    "                to be determined \n",
    "            } \n",
    "        } \n",
    "    } \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "cac50cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_character(name, data):\n",
    "    if name not in data.keys():\n",
    "        data[name] = {}\n",
    "        \n",
    "def add_season(season, name, data, seasons_episodes):\n",
    "    if season not in data[name].keys():\n",
    "        data[name][season] = {\n",
    "            \"episodes\": [],\n",
    "            \"words\": {},\n",
    "            \"n_words\": 0,\n",
    "            \"n_lines\": 0,\n",
    "            \"lines_per_ep\": {},\n",
    "            \"stop_words\": {},\n",
    "            \"n_stop_words\": 0\n",
    "        }\n",
    "    if season not in seasons_episodes.keys():\n",
    "        seasons_episodes[season] = {}\n",
    "        \n",
    "def add_episode(episode, season, name, data, seasons_episodes):\n",
    "    if episode not in data[name][season][\"episodes\"]:\n",
    "        data[name][season][\"episodes\"].append(episode)\n",
    "        data[name][season][\"lines_per_ep\"][episode] = 0\n",
    "    if episode not in seasons_episodes[season].keys():\n",
    "        seasons_episodes[season][episode] = 1\n",
    "    else:\n",
    "        seasons_episodes[season][episode] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "11a668ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_main_data(scripts, stop):\n",
    "    characters_data = {}\n",
    "    seasons_episodes = {}\n",
    "    stop_words = []\n",
    "    for row in scripts.itertuples():\n",
    "        add_character(row[6], characters_data)\n",
    "        add_season(row[2], row[6], characters_data, seasons_episodes)\n",
    "        add_episode(row[3], row[2], row[6], characters_data, seasons_episodes)\n",
    "\n",
    "    for row in stop.itertuples():\n",
    "        stop_words.append(re.sub('[^A-Za-z0-9]+', '', row[1]))\n",
    "    \n",
    "    return characters_data, seasons_episodes, stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18516f66",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe92fef",
   "metadata": {},
   "source": [
    "## Create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "4ff3b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_word(word, stop_words, season_data):\n",
    "    if word not in stop_words:\n",
    "        if word in season_data[\"words\"].keys():\n",
    "            season_data[\"words\"][word] += 1\n",
    "            season_data[\"n_words\"] += 1\n",
    "        else:\n",
    "            season_data[\"words\"][word] = 1\n",
    "            season_data[\"n_words\"] += 1\n",
    "    else:\n",
    "        if word in season_data[\"stop_words\"].keys():\n",
    "            season_data[\"stop_words\"][word] += 1\n",
    "            season_data[\"n_stop_words\"] += 1\n",
    "        else:\n",
    "            season_data[\"stop_words\"][word] = 1\n",
    "            season_data[\"n_stop_words\"] += 1\n",
    "\n",
    "def count_line(season_data, episode):\n",
    "    season_data[\"n_lines\"] += 1\n",
    "    season_data[\"lines_per_ep\"][episode] += 1\n",
    "\n",
    "characters_data, season_episodes, stop_words = generate_main_data(scripts_df, stop_words_df)\n",
    "\n",
    "for row in scripts_df.itertuples():\n",
    "    season_data = characters_data[row[6]][row[2]]\n",
    "    count_line(season_data, row[3])\n",
    "    for word in row[5].strip().split():\n",
    "        insert_word(re.sub('[^A-Za-z0-9]+', '', word), stop_words, season_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c0809",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0623f1",
   "metadata": {},
   "source": [
    "### How many characters? What are their names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "53de4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 793 characters in the series, their names are in \"names.txt\" file\n"
     ]
    }
   ],
   "source": [
    "n_characters = len(characters_data.keys())\n",
    "\n",
    "with open('names.txt', 'w') as names_output:\n",
    "    names_output.write(f\"{n_characters} characters in this file.\\n\\n\")\n",
    "    count = 1\n",
    "    for name in characters_data.keys():\n",
    "        names_output.write(str(count) + \" -> \" + name + \"\\n\")\n",
    "        count += 1\n",
    "\n",
    "print(f\"there are {n_characters} characters in the series, their names are in \\\"names.txt\\\" file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5fff8",
   "metadata": {},
   "source": [
    "### For each character, find out who has the most lines across all episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "3813b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charecter with the most lines across all the episodes is Michael, with 12140 lines.\n"
     ]
    }
   ],
   "source": [
    "most_lines = [\"\", 0]\n",
    "for name in characters_data.keys():\n",
    "    total_lines = 0\n",
    "    for season in characters_data[name].keys():\n",
    "        total_lines += characters_data[name][season][\"n_lines\"]\n",
    "    if total_lines > most_lines[1]:\n",
    "        most_lines[0] = name\n",
    "        most_lines[1] = total_lines\n",
    "print(f\"The charecter with the most lines across all the episodes is {most_lines[0]}, with {most_lines[1]} lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332213f9",
   "metadata": {},
   "source": [
    "### What is the average of words per line for each character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "1909c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in avg_words_per_line.csv\n"
     ]
    }
   ],
   "source": [
    "with open('avg_words_per_line.csv', 'w') as avg_words_output:\n",
    "    avg_words_output.write(f\"Name, avg_words_per_line\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        words = 0\n",
    "        lines = 0\n",
    "        for season in characters_data[name].keys():\n",
    "            words += characters_data[name][season][\"n_words\"]\n",
    "            lines += characters_data[name][season][\"n_lines\"]\n",
    "        avg_words_output.write(f\"{name},{words//lines}\\n\")\n",
    "\n",
    "print(\"The answer is in avg_words_per_line.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf46bc7",
   "metadata": {},
   "source": [
    "### What is the most common word per character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "7186d679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in common_words.csv\n"
     ]
    }
   ],
   "source": [
    "def most_common_word(words):\n",
    "    common = [\"\", 0]\n",
    "    if len(words.keys()) == 0:\n",
    "        return []\n",
    "    for key in words.keys():\n",
    "        if words[key] > common[1]:\n",
    "            common[0] = key\n",
    "            common[1] = words[key]\n",
    "    return common\n",
    "\n",
    "with open('common_words.csv', 'w') as common_words_output:\n",
    "    common_words_output.write(\"name,most_common_word\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        words_dict = {}\n",
    "        for season in characters_data[name].keys():\n",
    "            for key in characters_data[name][season][\"words\"].keys():\n",
    "                if key not in words_dict.keys():\n",
    "                    words_dict[key] = characters_data[name][season][\"words\"][key]\n",
    "                else:\n",
    "                    words_dict[key] += characters_data[name][season][\"words\"][key]\n",
    "        words_dict = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "        common = most_common_word(words_dict)\n",
    "        if len(common) == 0:\n",
    "            common = [\"Does not use words\"]\n",
    "        common_words_output.write(name + \",\" + common[0] + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"The answer is in common_words.csv\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d8d78",
   "metadata": {},
   "source": [
    "### Number of episodes where the character does not have a line, for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "26b7d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in episodes_without_line.csv\n"
     ]
    }
   ],
   "source": [
    "with open('episodes_without_lines.csv', 'w') as no_lines_output:\n",
    "    no_lines_output.write(\"name,number_of_episodes\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        no_lines = 0\n",
    "        for season in characters_data[name].keys():\n",
    "            no_lines += (len(season_episodes[season].keys()) - len(characters_data[name][season][\"episodes\"]))\n",
    "        no_lines_output.write(name + \",\" + str(no_lines) + \"\\n\")\n",
    "\n",
    "print(\"The answer is in episodes_without_line.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf8e3d",
   "metadata": {},
   "source": [
    "### Number of times \"That's what she said\" joke comes up & five examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "f7bdc098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 posible instances of \"That´s what she said\" jokes.\n",
      "The examples are in jokes.txt and were discovered by printing some of the posible jokes ids (the first and second id weren't jokes)\n"
     ]
    }
   ],
   "source": [
    "def get_posible_jokes(joke, scripts_data):\n",
    "    posible = []\n",
    "    joke = \"That's what she said\"\n",
    "    for row in scripts_data.itertuples():\n",
    "            if joke.lower() in row[5].lower():\n",
    "                posible.append(row[0])\n",
    "    return posible\n",
    "\n",
    "posible_jokes = get_posible_jokes(\"That's what she said\", scripts_df)\n",
    "print(f\"There are {len(posible_jokes)} posible instances of \\\"That´s what she said\\\" jokes.\")\n",
    "\n",
    "\n",
    "with open('jokes.txt', 'w') as jokes_output:\n",
    "    count = 1\n",
    "    for i in range(2, 8):\n",
    "        jokes_output.write(f\"Example {count}:\\n\")\n",
    "        count += 1\n",
    "        idx = posible_jokes[i] - 1\n",
    "        while idx <= posible_jokes[i] + 1:\n",
    "            jokes_output.write(scripts_df[\"speaker\"].iloc[idx] + \": \" + scripts_df[\"line_text\"].iloc[idx] + \"\\n\")\n",
    "            idx += 1\n",
    "        jokes_output.write(\"\\n\")\n",
    "\n",
    "print(\"The examples are in jokes.txt and were discovered by printing some of the posible jokes ids (the first and second id weren't jokes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3d406",
   "metadata": {},
   "source": [
    "### The average percent of lines each character contributed to each episode per season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "e84deab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in lines_per_episode.csv\n"
     ]
    }
   ],
   "source": [
    "with open(\"lines_per_episode.csv\", \"w\") as lines_per_episode:\n",
    "    lines_per_episode.write(\"name, season, episode, percentage_spoken\\n\")\n",
    "    for name in characters_data.keys():\n",
    "            for season in characters_data[name].keys():\n",
    "                for ep in characters_data[name][season][\"episodes\"]:\n",
    "                    spoken = characters_data[name][season][\"lines_per_ep\"][ep]\n",
    "                    total = season_episodes[season][ep]\n",
    "                    lines_per_episode.write(name + \",\" + str(season) + \",\" + str(ep) + \",\" + str(spoken*100/total) + \"\\n\")\n",
    "\n",
    "print(\"The answer is in lines_per_episode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de318f",
   "metadata": {},
   "source": [
    "## 3 questions inveted by me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78be5e",
   "metadata": {},
   "source": [
    "### Question 1: Per season, wich is the chapter with more scenes? and wich is the chapter with most stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40170dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b247d1c",
   "metadata": {},
   "source": [
    "### Question 2: Who is the character that uses the most stop words in the series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "75493543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charecter with the most stop words used across all the episodes is Michael, with 94057 stop words used.\n"
     ]
    }
   ],
   "source": [
    "most_stop_words = [\"\", 0]\n",
    "for name in characters_data.keys():\n",
    "    stop_words_used = 0\n",
    "    for season in characters_data[name].keys():\n",
    "        for key in characters_data[name][season][\"stop_words\"].keys():\n",
    "            stop_words_used += characters_data[name][season][\"stop_words\"][key]\n",
    "    if stop_words_used > most_stop_words[1]:\n",
    "        most_stop_words = [name, stop_words_used]\n",
    "print(f\"The charecter with the most stop words used across all the episodes is {most_stop_words[0]}, with {most_stop_words[1]} stop words used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05891e",
   "metadata": {},
   "source": [
    "### Question 3: Most common stop word per character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "78dade51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in common_stop_words.csv\n"
     ]
    }
   ],
   "source": [
    "with open('common_stop_words.csv', 'w') as stop_words_output:\n",
    "    stop_words_output.write(\"name,most_common_stop_word\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        words_dict = {}\n",
    "        for season in characters_data[name].keys():\n",
    "            for key in characters_data[name][season][\"stop_words\"].keys():\n",
    "                if key not in words_dict.keys():\n",
    "                    words_dict[key] = characters_data[name][season][\"stop_words\"][key]\n",
    "                else:\n",
    "                    words_dict[key] += characters_data[name][season][\"stop_words\"][key]\n",
    "        words_dict = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "        common = most_common_word(words_dict)\n",
    "        if len(common) == 0:\n",
    "            common = [\"Does not use stop words\"]\n",
    "        stop_words_output.write(name + \",\" + common[0] + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"The answer is in common_stop_words.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd82d1",
   "metadata": {},
   "source": [
    "## Additional questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db20e2",
   "metadata": {},
   "source": [
    "### What are the most critical challenges for Adara, related to data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134d74e",
   "metadata": {},
   "source": [
    "I belive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129c110",
   "metadata": {},
   "source": [
    "### Why did you choose this assignment instead of option 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55507cd9",
   "metadata": {},
   "source": [
    "I choose this asignment because its been a long time since Y was able to do \"data analysis\", so I wanted to see how I was doing and what I remembered from clases (Data analysis was one of my two minors, but because of curriculum problems I had to drop it). Also when people is trying to apply for a computer science job, usually, there's a Frontend/Backend assignment to solve and since I have been applying to different jobs I wanted to do something different to get out of the routine and to remember past knowledge (specialy still being in University and working in Frontend or Backend in almost all my courses)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928606d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee847152a79292afd68067fa7f82c76497e8ffb52646a4d733755f3444555193"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

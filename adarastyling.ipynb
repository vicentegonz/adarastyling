{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbfb958",
   "metadata": {},
   "source": [
    "# First aproach & Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9028b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vga19\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4be678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c530845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"./the_office_lines_scripts.csv\"\n",
    "json_file = \"./stopwords.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca87a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59904</th>\n",
       "      <td>59905</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>It all seems so very arbitrary. I applied for ...</td>\n",
       "      <td>Creed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59905</th>\n",
       "      <td>59906</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>I just feel lucky that I got a chance to share...</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>59907</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>114</td>\n",
       "      <td>I���m happy that this was all filmed so I can ...</td>\n",
       "      <td>Phyllis</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59907</th>\n",
       "      <td>59908</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>I sold paper at this company for 12 years. My ...</td>\n",
       "      <td>Jim</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59908</th>\n",
       "      <td>59909</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>116</td>\n",
       "      <td>I thought it was weird when you picked us to m...</td>\n",
       "      <td>Pam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59909 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  season  episode  scene  \\\n",
       "0          1       1        1      1   \n",
       "1          2       1        1      1   \n",
       "2          3       1        1      1   \n",
       "3          4       1        1      1   \n",
       "4          5       1        1      1   \n",
       "...      ...     ...      ...    ...   \n",
       "59904  59905       9       23    112   \n",
       "59905  59906       9       23    113   \n",
       "59906  59907       9       23    114   \n",
       "59907  59908       9       23    115   \n",
       "59908  59909       9       23    116   \n",
       "\n",
       "                                               line_text   speaker  deleted  \n",
       "0      All right Jim. Your quarterlies look very good...   Michael    False  \n",
       "1             Oh, I told you. I couldn't close it. So...       Jim    False  \n",
       "2      So you've come to the master for guidance? Is ...   Michael    False  \n",
       "3             Actually, you called me in here, but yeah.       Jim    False  \n",
       "4        All right. Well, let me show you how it's done.   Michael    False  \n",
       "...                                                  ...       ...      ...  \n",
       "59904  It all seems so very arbitrary. I applied for ...     Creed    False  \n",
       "59905  I just feel lucky that I got a chance to share...  Meredith    False  \n",
       "59906  I���m happy that this was all filmed so I can ...   Phyllis    False  \n",
       "59907  I sold paper at this company for 12 years. My ...       Jim    False  \n",
       "59908  I thought it was weird when you picked us to m...       Pam    False  \n",
       "\n",
       "[59909 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts_df = pd.read_csv(csv_file, encoding=\"utf_8\")\n",
    "scripts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d77e41",
   "metadata": {},
   "source": [
    "We would drop the deleted column as it won't be used in this activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa2b2508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>line_text</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>Jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>Jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59904</th>\n",
       "      <td>59905</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>It all seems so very arbitrary. I applied for ...</td>\n",
       "      <td>Creed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59905</th>\n",
       "      <td>59906</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>113</td>\n",
       "      <td>I just feel lucky that I got a chance to share...</td>\n",
       "      <td>Meredith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59906</th>\n",
       "      <td>59907</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>114</td>\n",
       "      <td>I���m happy that this was all filmed so I can ...</td>\n",
       "      <td>Phyllis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59907</th>\n",
       "      <td>59908</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>I sold paper at this company for 12 years. My ...</td>\n",
       "      <td>Jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59908</th>\n",
       "      <td>59909</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>116</td>\n",
       "      <td>I thought it was weird when you picked us to m...</td>\n",
       "      <td>Pam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59909 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  season  episode  scene  \\\n",
       "0          1       1        1      1   \n",
       "1          2       1        1      1   \n",
       "2          3       1        1      1   \n",
       "3          4       1        1      1   \n",
       "4          5       1        1      1   \n",
       "...      ...     ...      ...    ...   \n",
       "59904  59905       9       23    112   \n",
       "59905  59906       9       23    113   \n",
       "59906  59907       9       23    114   \n",
       "59907  59908       9       23    115   \n",
       "59908  59909       9       23    116   \n",
       "\n",
       "                                               line_text   speaker  \n",
       "0      All right Jim. Your quarterlies look very good...   Michael  \n",
       "1             Oh, I told you. I couldn't close it. So...       Jim  \n",
       "2      So you've come to the master for guidance? Is ...   Michael  \n",
       "3             Actually, you called me in here, but yeah.       Jim  \n",
       "4        All right. Well, let me show you how it's done.   Michael  \n",
       "...                                                  ...       ...  \n",
       "59904  It all seems so very arbitrary. I applied for ...     Creed  \n",
       "59905  I just feel lucky that I got a chance to share...  Meredith  \n",
       "59906  I���m happy that this was all filmed so I can ...   Phyllis  \n",
       "59907  I sold paper at this company for 12 years. My ...       Jim  \n",
       "59908  I thought it was weird when you picked us to m...       Pam  \n",
       "\n",
       "[59909 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts_df = scripts_df.drop([\"deleted\"], axis=1)\n",
    "scripts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31e984",
   "metadata": {},
   "source": [
    "we remove special separators, this way groups of characters won't be counted as a character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e393527",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(',', '+')\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace('/', '+')\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(' and ', '+')\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.replace(' & ', '+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a6ea1",
   "metadata": {},
   "source": [
    "we change every text to lower case so cases like Name and name won't be counted as different characters, also we remove leading and trailling whitespace to avoid any other problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe0ed002",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.lower()\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.lstrip()\n",
    "scripts_df[\"speaker\"] = scripts_df[\"speaker\"].str.rstrip()\n",
    "scripts_df[\"line_text\"] = scripts_df[\"line_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0147727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>thorough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>thoroughly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>wonder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0             a\n",
       "1         about\n",
       "2         above\n",
       "3         after\n",
       "4         again\n",
       "..          ...\n",
       "779    thorough\n",
       "780  thoroughly\n",
       "781       three\n",
       "782        well\n",
       "783      wonder\n",
       "\n",
       "[784 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_df = pd.read_json(json_file)\n",
    "stop_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40190dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>keeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "count     784\n",
       "unique    781\n",
       "top     keeps\n",
       "freq        2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f30a65",
   "metadata": {},
   "source": [
    "# Main data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474add5d",
   "metadata": {},
   "source": [
    "For easy access to the information we can transform the scripts_df into three main variables: \"characters_data\" which is a dictionary capable of telling all the seasons/episodes in which a character was present, it also has a place for season metadata to solve the tasks of this option (words, stop words and lines); \"stop_words\": A list with all the stop words lowered and formatted so everything is consistent; \"season_episodes\": A dictionary with the seasons as keys and a list of episodes as data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cac50cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_character(name, data):\n",
    "    if name not in data.keys():\n",
    "        data[name] = {}\n",
    "        \n",
    "def add_season(season, name, data, seasons_episodes):\n",
    "    if season not in data[name].keys():\n",
    "        data[name][season] = {\n",
    "            \"episodes\": [],\n",
    "            \"words\": {},\n",
    "            \"n_words\": 0,\n",
    "            \"n_lines\": 0,\n",
    "            \"lines_per_ep\": {},\n",
    "            \"stop_words\": {},\n",
    "            \"n_stop_words\": 0\n",
    "        }\n",
    "    if season not in seasons_episodes.keys():\n",
    "        seasons_episodes[season] = {}\n",
    "        \n",
    "def add_episode(episode, season, name, data, seasons_episodes):\n",
    "    if episode not in data[name][season][\"episodes\"]:\n",
    "        data[name][season][\"episodes\"].append(episode)\n",
    "        data[name][season][\"lines_per_ep\"][episode] = 0\n",
    "    if episode not in seasons_episodes[season].keys():\n",
    "        seasons_episodes[season][episode] = 1\n",
    "    else:\n",
    "        seasons_episodes[season][episode] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11a668ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_main_data(scripts, stop):\n",
    "    characters_data = {}\n",
    "    seasons_episodes = {}\n",
    "    stop_words = []\n",
    "    for row in scripts.itertuples():\n",
    "        if \"+\" in row[6]:\n",
    "            for character in row[6].split(\"+\"):\n",
    "                add_character(character.lstrip(), characters_data)\n",
    "                add_season(row[2], character.lstrip(), characters_data, seasons_episodes)\n",
    "                add_episode(row[3], row[2], character.lstrip(), characters_data, seasons_episodes)\n",
    "        else:\n",
    "            add_character(row[6], characters_data)\n",
    "            add_season(row[2], row[6], characters_data, seasons_episodes)\n",
    "            add_episode(row[3], row[2], row[6], characters_data, seasons_episodes)\n",
    "\n",
    "    for row in stop.itertuples():\n",
    "        stop_words.append(re.sub('[^A-Za-z0-9]+', '', row[1]).lower())\n",
    "    \n",
    "    return characters_data, seasons_episodes, stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18516f66",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe92fef",
   "metadata": {},
   "source": [
    "## Create metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51f11a",
   "metadata": {},
   "source": [
    "Using the main data we can now create the aditional information that will be used to solve the different questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff3b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_word(word, stop_words, season_data):\n",
    "    if word not in stop_words:\n",
    "        if word in season_data[\"words\"].keys():\n",
    "            season_data[\"words\"][word] += 1\n",
    "            season_data[\"n_words\"] += 1\n",
    "        else:\n",
    "            season_data[\"words\"][word] = 1\n",
    "            season_data[\"n_words\"] += 1\n",
    "    else:\n",
    "        if word in season_data[\"stop_words\"].keys():\n",
    "            season_data[\"stop_words\"][word] += 1\n",
    "            season_data[\"n_stop_words\"] += 1\n",
    "        else:\n",
    "            season_data[\"stop_words\"][word] = 1\n",
    "            season_data[\"n_stop_words\"] += 1\n",
    "\n",
    "def count_line(season_data, episode):\n",
    "    season_data[\"n_lines\"] += 1\n",
    "    season_data[\"lines_per_ep\"][episode] += 1\n",
    "\n",
    "characters_data, season_episodes, stop_words = generate_main_data(scripts_df, stop_words_df)\n",
    "\n",
    "for row in scripts_df.itertuples():\n",
    "    if \"+\" in row[6]:\n",
    "            for character in row[6].split(\"+\"):\n",
    "                season_data = characters_data[character.lstrip()][row[2]]\n",
    "                count_line(season_data, row[3])\n",
    "                for word in row[5].strip().split():\n",
    "                    insert_word(re.sub('[^A-Za-z0-9]+', '', word).lower(), stop_words, season_data)\n",
    "    else:\n",
    "        season_data = characters_data[row[6]][row[2]]\n",
    "        count_line(season_data, row[3])\n",
    "        for word in row[5].strip().split():\n",
    "            insert_word(re.sub('[^A-Za-z0-9]+', '', word).lower(), stop_words, season_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c0809",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c3d6e",
   "metadata": {},
   "source": [
    "Some questions are answered in this ipynb file and others are answered in a file that can be .txt or .csv. Also, the answer of the .csv files could be presented in only one file but for the assignment, I did it separately so each question has its answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0623f1",
   "metadata": {},
   "source": [
    "### How many characters? What are their names?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bac323",
   "metadata": {},
   "source": [
    "\"names.txt\" has the list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53de4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 704 characters in the series, their names are in \"names.txt\" file\n"
     ]
    }
   ],
   "source": [
    "n_characters = len(characters_data.keys())\n",
    "\n",
    "with open('names.txt', 'w') as names_output:\n",
    "    names_output.write(f\"{n_characters} characters in this file.\\n\\n\")\n",
    "    count = 1\n",
    "    for name in characters_data.keys():\n",
    "        names_output.write(str(count) + \" -> \" + name + \"\\n\")\n",
    "        count += 1\n",
    "\n",
    "print(f\"there are {n_characters} characters in the series, their names are in \\\"names.txt\\\" file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5fff8",
   "metadata": {},
   "source": [
    "### For each character, find out who has the most lines across all episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5f036",
   "metadata": {},
   "source": [
    "Michael, and he has 12140 lines across the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3813b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charecter with the most lines across all the episodes is michael, with 12189 lines.\n"
     ]
    }
   ],
   "source": [
    "most_lines = [\"\", 0]\n",
    "for name in characters_data.keys():\n",
    "    total_lines = 0\n",
    "    for season in characters_data[name].keys():\n",
    "        total_lines += characters_data[name][season][\"n_lines\"]\n",
    "    if total_lines > most_lines[1]:\n",
    "        most_lines[0] = name\n",
    "        most_lines[1] = total_lines\n",
    "print(f\"The charecter with the most lines across all the episodes is {most_lines[0]}, with {most_lines[1]} lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332213f9",
   "metadata": {},
   "source": [
    "### What is the average of words per line for each character?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b938cf",
   "metadata": {},
   "source": [
    "\"avg_words_per_line.csv\" has the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1909c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in avg_words_per_line.csv\n"
     ]
    }
   ],
   "source": [
    "with open('avg_words_per_line.csv', 'w') as avg_words_output:\n",
    "    avg_words_output.write(f\"Name, avg_words_per_line\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        words = 0\n",
    "        lines = 0\n",
    "        for season in characters_data[name].keys():\n",
    "            words += characters_data[name][season][\"n_words\"]\n",
    "            lines += characters_data[name][season][\"n_lines\"]\n",
    "        avg_words_output.write(f\"{name},{words//lines}\\n\")\n",
    "\n",
    "print(\"The answer is in avg_words_per_line.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf46bc7",
   "metadata": {},
   "source": [
    "### What is the most common word per character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76126ac7",
   "metadata": {},
   "source": [
    "\"common_words.csv\" has the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7186d679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in common_words.csv\n"
     ]
    }
   ],
   "source": [
    "def most_common_word(words):\n",
    "    common = [\"\", 0]\n",
    "    if len(words.keys()) == 0:\n",
    "        return []\n",
    "    for key in words.keys():\n",
    "        if words[key] > common[1]:\n",
    "            common[0] = key\n",
    "            common[1] = words[key]\n",
    "    return common\n",
    "\n",
    "with open('common_words.csv', 'w') as common_words_output:\n",
    "    common_words_output.write(\"name,most_common_word\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        words_dict = {}\n",
    "        for season in characters_data[name].keys():\n",
    "            for key in characters_data[name][season][\"words\"].keys():\n",
    "                if key not in words_dict.keys():\n",
    "                    words_dict[key] = characters_data[name][season][\"words\"][key]\n",
    "                else:\n",
    "                    words_dict[key] += characters_data[name][season][\"words\"][key]\n",
    "        words_dict = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "        common = most_common_word(words_dict)\n",
    "        if len(common) == 0:\n",
    "            common = [\"Does not use words\"]\n",
    "        common_words_output.write(name + \",\" + common[0] + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"The answer is in common_words.csv\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d8d78",
   "metadata": {},
   "source": [
    "### Number of episodes where the character does not have a line, for each character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99325b82",
   "metadata": {},
   "source": [
    "\"episodes_without_line.csv\" has the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26b7d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in episodes_without_line.csv\n"
     ]
    }
   ],
   "source": [
    "with open('episodes_without_lines.csv', 'w') as no_lines_output:\n",
    "    no_lines_output.write(\"name,number_of_episodes\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        no_lines = 0\n",
    "        for season in characters_data[name].keys():\n",
    "            no_lines += (len(season_episodes[season].keys()) - len(characters_data[name][season][\"episodes\"]))\n",
    "        no_lines_output.write(name + \",\" + str(no_lines) + \"\\n\")\n",
    "\n",
    "print(\"The answer is in episodes_without_line.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf8e3d",
   "metadata": {},
   "source": [
    "### Number of times \"That's what she said\" joke comes up & five examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9401f93",
   "metadata": {},
   "source": [
    "There are 37 posible jokes, and the examples are in \"jokes.txt\". This file was created through trial an error until 5 jokes where obtained (the 1st and 2nd posible jokes weren't jokes, but usual dialog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7bdc098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 posible instances of \"That´s what she said\" jokes.\n",
      "The examples are in jokes.txt and were discovered by printing some of the posible jokes ids (the first and second id weren't jokes)\n"
     ]
    }
   ],
   "source": [
    "def get_posible_jokes(joke, scripts_data):\n",
    "    posible = []\n",
    "    joke = \"That's what she said\"\n",
    "    for row in scripts_data.itertuples():\n",
    "            if joke.lower() in row[5].lower():\n",
    "                posible.append(row[0])\n",
    "    return posible\n",
    "\n",
    "posible_jokes = get_posible_jokes(\"That's what she said\", scripts_df)\n",
    "print(f\"There are {len(posible_jokes)} posible instances of \\\"That´s what she said\\\" jokes.\")\n",
    "\n",
    "\n",
    "with open('jokes.txt', 'w') as jokes_output:\n",
    "    count = 1\n",
    "    for i in range(2, 8):\n",
    "        jokes_output.write(f\"Example {count}:\\n\")\n",
    "        count += 1\n",
    "        idx = posible_jokes[i] - 1\n",
    "        while idx <= posible_jokes[i] + 1:\n",
    "            jokes_output.write(scripts_df[\"speaker\"].iloc[idx] + \": \" + scripts_df[\"line_text\"].iloc[idx] + \"\\n\")\n",
    "            idx += 1\n",
    "        jokes_output.write(\"\\n\")\n",
    "\n",
    "print(\"The examples are in jokes.txt and were discovered by printing some of the posible jokes ids (the first and second id weren't jokes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3d406",
   "metadata": {},
   "source": [
    "### The average percent of lines each character contributed to each episode per season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb060b",
   "metadata": {},
   "source": [
    "\"lines_per_episode.csv\" has the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e84deab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in lines_per_episode.csv\n"
     ]
    }
   ],
   "source": [
    "with open(\"lines_per_episode.csv\", \"w\") as lines_per_episode:\n",
    "    lines_per_episode.write(\"name, season, episode, percentage_spoken\\n\")\n",
    "    for name in characters_data.keys():\n",
    "            for season in characters_data[name].keys():\n",
    "                for ep in characters_data[name][season][\"episodes\"]:\n",
    "                    spoken = characters_data[name][season][\"lines_per_ep\"][ep]\n",
    "                    total = season_episodes[season][ep]\n",
    "                    lines_per_episode.write(name + \",\" + str(season) + \",\" + str(ep) + \",\" + str(spoken*100/total) + \"\\n\")\n",
    "\n",
    "print(\"The answer is in lines_per_episode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de318f",
   "metadata": {},
   "source": [
    "## 3 questions inveted by me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78be5e",
   "metadata": {},
   "source": [
    "### Question 1: Per season, wich is the episode/s with more scenes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee540c",
   "metadata": {},
   "source": [
    "\"most_scenes.txt\" has the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40170dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in the \"most_scenes.txt\" file.\n"
     ]
    }
   ],
   "source": [
    "with open('most_scenes.txt', 'w') as scenes_output:\n",
    "    for season in season_episodes.keys():\n",
    "        more_scenes = 0\n",
    "        episodes_list = []\n",
    "        for ep in season_episodes[season].keys():\n",
    "            n_scenes = len(scripts_df[(scripts_df[\"season\"] == season) & (scripts_df[\"episode\"] == ep)].groupby([\"scene\"]).count())\n",
    "            if n_scenes > more_scenes:\n",
    "                more_scenes = n_scenes\n",
    "                episodes_list = [ep]\n",
    "            elif n_scenes == more_scenes:\n",
    "                episodes_list.append(ep)\n",
    "        scenes_output.write(f\"The most scenes in Season {season} are {more_scenes} scenes and they are in the next episode/s:\\n\")\n",
    "        for ep in episodes_list:\n",
    "            scenes_output.write(f\"Episode: {ep}\\n\")\n",
    "        scenes_output.write(\"\\n\")\n",
    "print(\"The answer is in the \\\"most_scenes.txt\\\" file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b247d1c",
   "metadata": {},
   "source": [
    "### Question 2: Who is the character that uses the most stop words in the series?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa6a30",
   "metadata": {},
   "source": [
    "Michael has the most stop words used in the series and he uses a total of 121190 stop words (times used not different stop words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75493543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The charecter with the most stop words used across all the episodes is michael, with 121543 stop words used.\n"
     ]
    }
   ],
   "source": [
    "most_stop_words = [\"\", 0]\n",
    "for name in characters_data.keys():\n",
    "    stop_words_used = 0\n",
    "    for season in characters_data[name].keys():\n",
    "        for key in characters_data[name][season][\"stop_words\"].keys():\n",
    "            stop_words_used += characters_data[name][season][\"stop_words\"][key]\n",
    "    if stop_words_used > most_stop_words[1]:\n",
    "        most_stop_words = [name, stop_words_used]\n",
    "print(f\"The charecter with the most stop words used across all the episodes is {most_stop_words[0]}, with {most_stop_words[1]} stop words used.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05891e",
   "metadata": {},
   "source": [
    "### Question 3: Most common stop word per character?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbcd126",
   "metadata": {},
   "source": [
    "\"common_stop_words.csv\" has the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78dade51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is in common_stop_words.csv\n"
     ]
    }
   ],
   "source": [
    "with open('common_stop_words.csv', 'w') as stop_words_output:\n",
    "    stop_words_output.write(\"name,most_common_stop_word\\n\")\n",
    "    for name in characters_data.keys():\n",
    "        words_dict = {}\n",
    "        for season in characters_data[name].keys():\n",
    "            for key in characters_data[name][season][\"stop_words\"].keys():\n",
    "                if key not in words_dict.keys():\n",
    "                    words_dict[key] = characters_data[name][season][\"stop_words\"][key]\n",
    "                else:\n",
    "                    words_dict[key] += characters_data[name][season][\"stop_words\"][key]\n",
    "        words_dict = {k: v for k, v in sorted(words_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "        common = most_common_word(words_dict)\n",
    "        if len(common) == 0:\n",
    "            common = [\"Does not use stop words\"]\n",
    "        stop_words_output.write(name + \",\" + common[0] + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"The answer is in common_stop_words.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd82d1",
   "metadata": {},
   "source": [
    "## Additional questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db20e2",
   "metadata": {},
   "source": [
    "### What are the most critical challenges for Adara, related to data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134d74e",
   "metadata": {},
   "source": [
    "starting in Data science has many problems, but I believe these are the main 2 problems Adara could find according to its current state:\n",
    "\n",
    "<li>Obtaining new data: Acquire new data is always hard especially when one is just starting, as Diego told me in the first meeting Adara is getting its data through polls on Instagram, so this means it's open to problems like having one user answer multiple times using different accounts which can lead to repeated data or non-representative data, being dependant of the store popularity as it's the buyers of the store the ones that fill out the polls and many others. I think that with the right tools like Instagram analytics (feature included in business accounts), and store data (most bought items, clicks on page ...etc) the collection of data could be improved and adjusted to have more of it and with fewer outliers. <br><br>\n",
    "\n",
    "<li>Obteining unbiased data: This problem is a derivative of the previous one because if Adara is only using one source of information to obtain its data there is a higher chance that this data is biased towards the store's usual client. For example, if a new client approaches the system and its style is different than most clients he/she could be pushed away because the recommendations don't adjust to his/her taste. Maybe including other sources of data or techniques could adjust the system to include new clients (weighted models, using other store clients to fill the Adaras poll ...etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129c110",
   "metadata": {},
   "source": [
    "### Why did you choose this assignment instead of option 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55507cd9",
   "metadata": {},
   "source": [
    "I choose this assignment because it's been a long time since I was able to do \"data analysis\", so I wanted to see how I was doing and what I remembered from classes (Data analysis was one of my two minors, but because of curriculum problems I had to drop it). Also when people are trying to apply for a computer science job, usually, there's a Frontend/Backend assignment to solve and since I have been applying to different jobs I wanted to do something different to get out of the routine and to remember past knowledge (especially still being in University and working in Frontend or Backend in almost all my courses)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee847152a79292afd68067fa7f82c76497e8ffb52646a4d733755f3444555193"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
